{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwZdEiaD7xrU"
      },
      "source": [
        "#### v1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_i9oe067xe1"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3ZQNk9n7upa"
      },
      "outputs": [],
      "source": [
        "pip install -qU langchain-groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pcJ7rm88AMV"
      },
      "outputs": [],
      "source": [
        "pip install -qU langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu5SBks9D_0_"
      },
      "outputs": [],
      "source": [
        "!pip install rouge-score nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import pymongo\n",
        "import pprint\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from rouge_score import rouge_scorer\n",
        "from nltk.translate.meteor_score import meteor_score\n",
        "import nltk\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from pymongo import MongoClient\n",
        "from langchain_community.document_loaders import DirectoryLoader"
      ],
      "metadata": {
        "id": "Y7xLYgeJZ3v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure NLTK resources are downloaded\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "C45YyH1fZ49K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AR9Ni8A8CnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b0d1a2-fd8f-4fbc-8812-bbe8ba3bcd05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWUz8nkL8P8e"
      },
      "outputs": [],
      "source": [
        "pip install -qU langchain-mongodb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0sGk1P-BoLt"
      },
      "outputs": [],
      "source": [
        "!pip install pymongo pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxHsPtl5BsmY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClhEIEXlZ0Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oTN6ixZAluH",
        "outputId": "e633dbd9-d7df-4ecf-c4f0-1ab832948821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MongoDB Atlas Cluster URI:··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "\n",
        "MONGODB_ATLAS_CLUSTER_URI = getpass.getpass(\"MongoDB Atlas Cluster URI:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8Cpm29yBNnn"
      },
      "outputs": [],
      "source": [
        "from pymongo import MongoClient\n",
        "from pymongo.operations import SearchIndexModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP2Kp32eA8aq"
      },
      "outputs": [],
      "source": [
        "# mongodb Atlas cluster connection\n",
        "client = MongoClient(MONGODB_ATLAS_CLUSTER_URI)\n",
        "\n",
        "# mongodb collection and index name\n",
        "db_name = \"v1_copilot\"\n",
        "collection_name = \"v2\"\n",
        "atlas_collection = client[db_name][collection_name]\n",
        "vector_search_index = \"copilot_index\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "IpSvA73nS4qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTAWmoXUBgk9"
      },
      "outputs": [],
      "source": [
        "# Load the PDF\n",
        "folder_path = \"/content/drive/MyDrive/downloaded_documents\"\n",
        "# Instead of using '../', use the actual folder path\n",
        "loader = DirectoryLoader(folder_path, glob=\"**/*.pdf\", show_progress=True , loader_cls = PyPDFLoader)\n",
        "# loader = PyPDFLoader(\"https://arxiv.org/pdf/2501.01478\")\n",
        "data = loader.load()\n",
        "\n",
        "# Split PDF into documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(data)\n",
        "\n",
        "# Print the first document\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKzHKnIrB3cu"
      },
      "outputs": [],
      "source": [
        "# Create the vector store\n",
        "vector_store = MongoDBAtlasVectorSearch.from_documents(\n",
        "    documents = docs,\n",
        "    embedding = OpenAIEmbeddings(disallowed_special=()),\n",
        "    collection = atlas_collection,\n",
        "    index_name = vector_search_index\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nlxauFU8S5b"
      },
      "outputs": [],
      "source": [
        "# Use helper method to create the vector search index\n",
        "vector_store.create_vector_search_index(\n",
        "   dimensions = 1536,\n",
        "   filters = [ \"page\" ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGsaPZp5C3d-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Instantiate Atlas Vector Search as a retriever\n",
        "\n",
        "# #### expriment around retriever\n",
        "  #### setup RAG evals using RAGAS/custom\n",
        "  #### create test dataset\n",
        "# retriever = vector_store.as_retriever(\n",
        "#    search_type = \"similarity\",\n",
        "#    search_kwargs = { \"k\": 15 }\n",
        "# )\n",
        "retriever = MongoDBAtlasVectorSearch(\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    collection=atlas_collection,\n",
        "    index_name=vector_search_index,\n",
        "    relevance_score_fn=\"cosine\",\n",
        "    search_type = \"similarity\",\n",
        "    search_kwargs = { \"k\": 15 }\n",
        ").as_retriever()\n",
        "\n",
        "#prompt template\n",
        "template = \"\"\" You are a kind and helpful QnA assistant. Your job is to assist Faculty and students of BITS Pilani in resolving their doubts and queries.\n",
        "   {context}\n",
        "   Question: {question}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "model = ChatOpenAI(openai_api_key = \"\")\n",
        "\n",
        "# llm chain\n",
        "chain = (\n",
        "   { \"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "   | prompt\n",
        "   | model\n",
        "   | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Prompt the chain\n",
        "# question = \"\"\"What are the guidelines for availing casual leaves by a PhD student?\"\"\"\n",
        "# answer = chain.invoke(question)\n",
        "\n",
        "# print(\"Question: \" + question)\n",
        "# print(\"Answer: \" + answer)\n",
        "\n",
        "# # Return source documents\n",
        "# documents = retriever.invoke(question)\n",
        "# print(\"\\nSource documents:\")\n",
        "# pprint.pprint(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation functions\n",
        "def exact_match_score(pred, truth):\n",
        "    return int(pred.strip().lower() == truth.strip().lower())\n",
        "\n",
        "def f1_score_token(pred, truth):\n",
        "    pred_tokens = pred.strip().lower().split()\n",
        "    truth_tokens = truth.strip().lower().split()\n",
        "    common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "    if len(common_tokens) == 0:\n",
        "        return 0.0\n",
        "    precision = len(common_tokens) / len(pred_tokens)\n",
        "    recall = len(common_tokens) / len(truth_tokens)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def bleu_score(pred, truth):\n",
        "    pred_tokens = pred.strip().lower().split()\n",
        "    truth_tokens = [truth.strip().lower().split()]\n",
        "    return sentence_bleu(truth_tokens, pred_tokens)\n",
        "\n",
        "def rouge_score(pred, truth):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    scores = scorer.score(truth.strip().lower(), pred.strip().lower())\n",
        "    return scores['rougeL'].fmeasure\n",
        "\n",
        "def meteor_score_custom(pred, truth):\n",
        "    return meteor_score([truth.strip().lower().split()], pred.strip().lower().split())\n",
        "\n",
        "# Load the CSV file containing question-answer pairs\n",
        "csv_path = \"/content/drive/MyDrive/IR_test_dataset.csv\"  # Replace with your CSV file path\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Initialize a list to store results\n",
        "results = []\n",
        "\n",
        "# Iterate over each question-answer pair\n",
        "for index, row in df.iterrows():\n",
        "    question = row[\"Question\"]\n",
        "    ground_truth_answer = row[\"Answer\"]\n",
        "\n",
        "    # Generate answer using the RAG system\n",
        "    generated_answer = chain.invoke(question)\n",
        "\n",
        "    # Evaluate the generated answer\n",
        "    em = exact_match_score(generated_answer, ground_truth_answer)\n",
        "    f1 = f1_score_token(generated_answer, ground_truth_answer)\n",
        "    bleu = bleu_score(generated_answer, ground_truth_answer)\n",
        "    rouge = rouge_score(generated_answer, ground_truth_answer)\n",
        "    meteor = meteor_score_custom(generated_answer, ground_truth_answer)\n",
        "\n",
        "    # Store results\n",
        "    results.append({\n",
        "        \"question\": question,\n",
        "        \"ground_truth_answer\": ground_truth_answer,\n",
        "        \"generated_answer\": generated_answer,\n",
        "        \"exact_match\": em,\n",
        "        \"f1_score\": f1,\n",
        "        \"bleu_score\": bleu,\n",
        "        \"rouge_score\": rouge,\n",
        "        \"meteor_score\": meteor\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results  CSV\n",
        "results_df.to_csv(\"/content/drive/MyDrive/IR_Project/v2_index.csv\", index=False)\n",
        "\n",
        "# Printscores\n",
        "print(\"Average Scores:\")\n",
        "print(f\"Exact Match: {results_df['exact_match'].mean()}\")\n",
        "print(f\"F1 Score: {results_df['f1_score'].mean()}\")\n",
        "print(f\"BLEU Score: {results_df['bleu_score'].mean()}\")\n",
        "print(f\"ROUGE Score: {results_df['rouge_score'].mean()}\")\n",
        "print(f\"METEOR Score: {results_df['meteor_score'].mean()}\")"
      ],
      "metadata": {
        "id": "V9NyMzkTYHwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5UKCdLpMYHtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kW2wsyeJYHqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxGkkZNuYHnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XXV_Roh2Yxg6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}